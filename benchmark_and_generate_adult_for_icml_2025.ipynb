{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c3723d-0905-471c-b56b-8c67b28b3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install synthcity\n",
    "!pip uninstall -y torchaudio torchdata\n",
    "!pip install openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8418da6a-44f0-462a-af53-bd170c266a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source code\n",
    "\n",
    "import os\n",
    "\n",
    "code_path = 'code/'\n",
    "\n",
    "# source utility functions \n",
    "file_path = os.path.join(code_path, 'utility_functions_syn_tab_sjppds_for_icml_2025.py')\n",
    "with open(os.path.expanduser(file_path)) as file:\n",
    "    exec(file.read())\n",
    "\n",
    "# source additional utility functions \n",
    "file_path = os.path.join(code_path, 'utility_functions_additional_for_icml_2025.py')\n",
    "with open(os.path.expanduser(file_path)) as file:\n",
    "    exec(file.read())\n",
    "\n",
    "# source the synth_tab_sjppds method synthcity plugin\n",
    "file_path = os.path.join(code_path, 'syn_tab_sjppds_synthcity_plugin_for_icml_2025.py')\n",
    "with open(os.path.expanduser(file_path)) as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3603b1f1-2121-48d6-bb63-79c30b98a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthcity absolute\n",
    "from synthcity.plugins import Plugins\n",
    "\n",
    "generators = Plugins()\n",
    "\n",
    "generators.add(\"syn_tab_sjppds\", SynTabSjppdsPlugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0d45b-81bc-44c5-aecb-aea76ae9146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "openml_data = fetch_openml(name=\"adult\", as_frame=True, version=1)\n",
    "\n",
    "# Get the features and target as DataFrames\n",
    "X = openml_data.data  # Features (pandas DataFrame)\n",
    "y = openml_data.target  # Target (pandas Series)\n",
    "\n",
    "X[\"target\"] = y\n",
    "\n",
    "X = X.dropna()\n",
    "\n",
    "X = process_adult_data(X)\n",
    "\n",
    "num_idx = [2, 4]\n",
    "cat_idx = [0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "X = enforce_dtypes(dat = X, \n",
    "                   num_variables = num_idx, \n",
    "                   cat_variables = cat_idx)\n",
    "\n",
    "# Split the data\n",
    "aux = train_test_data_split(X, my_seed=123)\n",
    "\n",
    "X_train = aux[\"X_train\"]\n",
    "X_test = aux[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2833ab-584f-40bd-a634-99fe29c316cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = GenericDataLoader(\n",
    "    X_train,\n",
    "    target_column = 'target'\n",
    ")\n",
    "\n",
    "loader_test = GenericDataLoader(\n",
    "    X_test,\n",
    "    target_column = 'target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d99beb-3536-4a59-87f8-3e4468e52bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthcity.benchmark import Benchmarks\n",
    "\n",
    "out_path = 'outputs/adult/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a35f248-bfb0-4204-9eac-71e9e5105afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = Benchmarks.evaluate(\n",
    "    [\n",
    "        ('TabSDS', 'syn_tab_sjppds', {'n_levels': 20, \n",
    "                                      'n_prop': 0.5, \n",
    "                                      \"num_variables\": num_idx, \n",
    "                                      \"cat_variables\": cat_idx}),\n",
    "        ('ddpm', 'ddpm', {'lr': 0.0009375080542687667,\n",
    "                          'batch_size': 2929,\n",
    "                          'num_timesteps': 998,\n",
    "                          'n_iter': 1051,\n",
    "                          'is_classification': True}),\n",
    "        ('arf', 'arf', {}),\n",
    "        ('tvae', 'tvae', {'n_iter': 300,\n",
    "                          'lr': 0.0002,\n",
    "                          'decoder_n_layers_hidden': 4,\n",
    "                          'weight_decay': 0.001,\n",
    "                          'batch_size': 256,\n",
    "                          'n_units_embedding': 200,\n",
    "                          'decoder_n_units_hidden': 300,\n",
    "                          'decoder_nonlin': 'elu',\n",
    "                          'decoder_dropout': 0.194325119117226,\n",
    "                          'encoder_n_layers_hidden': 1,\n",
    "                          'encoder_n_units_hidden': 450,\n",
    "                          'encoder_nonlin': 'leaky_relu',\n",
    "                          'encoder_dropout': 0.04288563703094718}),\n",
    "        ('ctgan', 'ctgan', {'generator_n_layers_hidden': 2,\n",
    "                            'generator_n_units_hidden': 50,\n",
    "                            'generator_nonlin': 'tanh',\n",
    "                            'n_iter': 1000,\n",
    "                            'generator_dropout': 0.0575,\n",
    "                            'discriminator_n_layers_hidden': 4,\n",
    "                            'discriminator_n_units_hidden': 150,\n",
    "                            'discriminator_nonlin': 'relu'}),\n",
    "        ('bayesnet', 'bayesian_network', {'struct_learning_search_method': 'hillclimb',\n",
    "                                            'struct_learning_score': 'bic'}),\n",
    "    ],\n",
    "    X=loader_train,\n",
    "    X_test=loader_test,\n",
    "    repeats=10,\n",
    "    metrics={\"performance\": [\"xgb\"],\n",
    "             \"detection\": [\"detection_xgb\"], \n",
    "             \"privacy\": [\"DomiasMIA_KDE\", \"DomiasMIA_prior\"]},\n",
    "    task_type = \"classification\",\n",
    ")\n",
    "\n",
    "# save results\n",
    "\n",
    "synthesizer_names = ['TabSDS', 'ddpm', 'arf', 'tvae', 'ctgan', 'bayesnet']\n",
    "\n",
    "mean1 = extract_summary(score_output = score1,\n",
    "                          synthesizer_names = synthesizer_names,\n",
    "                          summary_name = \"mean\")\n",
    "stddev1 = extract_summary(score_output = score1,\n",
    "                          synthesizer_names = synthesizer_names,\n",
    "                          summary_name = \"stddev\")\n",
    "\n",
    "file_name = os.path.join(out_path, \"adult_mean1.csv\")\n",
    "mean1.to_csv(file_name, index = True)\n",
    "\n",
    "file_name = os.path.join(out_path, \"adult_stddev1.csv\")\n",
    "stddev1.to_csv(file_name, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4055cd3d-107b-4558-960e-fbce0fbfc54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Benchmarks.print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4159de70-3d18-4d38-a490-1cfcdfbbcb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = 'outputs/adult/simulated_datasets/'\n",
    "\n",
    "file_name = os.path.join(out_path, 'train_set.csv')\n",
    "X_train.to_csv(file_name, index = False)\n",
    "\n",
    "file_name = os.path.join(out_path, 'test_set.csv')\n",
    "X_test.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417777be-175b-4284-b2c0-a01acdd3ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddpm\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "syn_model = Plugins().get('ddpm',\n",
    "                          n_iter = 1051,\n",
    "                          lr = 0.0009375080542687667,\n",
    "                          batch_size = 2929,\n",
    "                          num_timesteps = 998,\n",
    "                          is_classification = True)\n",
    "\n",
    "syn_model.fit(loader_train)\n",
    "\n",
    "n = len(loader_train)\n",
    "Y = syn_model.generate(count=n).dataframe()\n",
    "\n",
    "file_name = os.path.join(out_path, 'syn_ddpm.csv')\n",
    "Y.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f46d91-338d-4428-8275-ebe5fc42e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arf\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "syn_model = Plugins().get('arf')\n",
    "\n",
    "syn_model.fit(loader_train)\n",
    "\n",
    "n = len(loader_train)\n",
    "Y = syn_model.generate(count=n).dataframe()\n",
    "\n",
    "file_name = os.path.join(out_path, 'syn_arf.csv')\n",
    "Y.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe2061a-2527-4360-b96a-1cdb9a5a2407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvae\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "syn_model = Plugins().get('tvae', \n",
    "                          n_iter = 300,\n",
    "                          lr = 0.0002,\n",
    "                          decoder_n_layers_hidden = 4,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 256,\n",
    "                          n_units_embedding = 200,\n",
    "                          decoder_n_units_hidden = 300,\n",
    "                          decoder_nonlin = \"elu\",\n",
    "                          decoder_dropout = 0.194325119117226,\n",
    "                          encoder_n_layers_hidden = 1,\n",
    "                          encoder_n_units_hidden = 450,\n",
    "                          encoder_nonlin = \"leaky_relu\",\n",
    "                          encoder_dropout = 0.04288563703094718)\n",
    "\n",
    "syn_model.fit(loader_train)\n",
    "\n",
    "n = len(loader_train)\n",
    "Y = syn_model.generate(count=n).dataframe()\n",
    "\n",
    "file_name = os.path.join(out_path, 'syn_tvae.csv')\n",
    "Y.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89dce81-a9b7-4e58-b43c-7cd2a257684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctgan\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "syn_model = Plugins().get('ctgan',\n",
    "                            n_iter = 1000,\n",
    "                            generator_n_layers_hidden = 2,\n",
    "                            generator_n_units_hidden = 50,\n",
    "                            generator_nonlin = \"tanh\",\n",
    "                            generator_dropout = 0.0575,\n",
    "                            discriminator_n_layers_hidden = 4,\n",
    "                            discriminator_n_units_hidden = 150,\n",
    "                            discriminator_nonlin = \"relu\")\n",
    "\n",
    "syn_model.fit(loader_train)\n",
    "\n",
    "n = len(loader_train)\n",
    "Y = syn_model.generate(count=n).dataframe()\n",
    "\n",
    "file_name = os.path.join(out_path, 'syn_ctgan.csv')\n",
    "Y.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9797f0-5902-428f-9aab-cda4c27b0f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesnet\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "syn_model = Plugins().get('bayesian_network',\n",
    "                          struct_learning_search_method = 'hillclimb',\n",
    "                          struct_learning_score = 'bic')\n",
    "\n",
    "syn_model.fit(loader_train)\n",
    "\n",
    "n = len(loader_train)\n",
    "Y = syn_model.generate(count=n).dataframe()\n",
    "\n",
    "file_name = os.path.join(out_path, 'syn_bayesnet.csv')\n",
    "Y.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c240603-3148-4a1c-8cd1-fcc4f218df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syn_tab_sjppds\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "syn_model = Plugins().get('syn_tab_sjppds', \n",
    "                          num_variables = num_idx,\n",
    "                          cat_variables = cat_idx,\n",
    "                          n_levels = 20,\n",
    "                         n_prop = 0.5)\n",
    "\n",
    "syn_model.fit(loader_train)\n",
    "\n",
    "n = len(loader_train)\n",
    "Y = syn_model.generate(count=n).dataframe()\n",
    "\n",
    "file_name = os.path.join(out_path, 'syn_tab_sjppds_20_0.5.csv')\n",
    "Y.to_csv(file_name, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
