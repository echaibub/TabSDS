{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2445b427-1e27-4fa0-bc09-48d50574b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install synthcity\n",
    "!pip uninstall -y torchaudio torchdata\n",
    "!pip install openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a54e6-e686-41f9-b3fb-6e8835ffd916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source code\n",
    "\n",
    "import timeit\n",
    "\n",
    "# source code\n",
    "\n",
    "import os\n",
    "\n",
    "code_path = 'code/'\n",
    "\n",
    "# source utility functions \n",
    "file_path = os.path.join(code_path, 'utility_functions_syn_tab_sjppds_for_icml_2025.py')\n",
    "with open(os.path.expanduser(file_path)) as file:\n",
    "    exec(file.read())\n",
    "\n",
    "# source additional utility functions \n",
    "file_path = os.path.join(code_path, 'utility_functions_additional_for_icml_2025.py')\n",
    "with open(os.path.expanduser(file_path)) as file:\n",
    "    exec(file.read())\n",
    "\n",
    "# source the synth_tab_sjppds method synthcity plugin\n",
    "file_path = os.path.join(code_path, 'syn_tab_sjppds_synthcity_plugin_for_icml_2025.py')\n",
    "with open(os.path.expanduser(file_path)) as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c0597-4a1f-419a-a411-9049db64bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthcity absolute\n",
    "from synthcity.plugins import Plugins\n",
    "\n",
    "generators = Plugins()\n",
    "\n",
    "generators.add(\"syn_tab_sjppds\", SynTabSjppdsPlugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db082e7-05c8-45a8-82ff-840e4ac6806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_repli = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a59597-7714-4a9a-8fea-c90adc2df74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load the dataset\n",
    "california_housing = fetch_california_housing(as_frame=True)\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = california_housing.data\n",
    "y = california_housing.target\n",
    "\n",
    "X[\"target\"] = y\n",
    "\n",
    "num_idx = list(range(9))\n",
    "cat_idx = None\n",
    "\n",
    "X = enforce_dtypes(dat = X, \n",
    "                   num_variables = num_idx, \n",
    "                   cat_variables = cat_idx)\n",
    "\n",
    "# Split the data\n",
    "aux = train_test_data_split(X, my_seed=123)\n",
    "\n",
    "X_train = aux[\"X_train\"]\n",
    "X_test = aux[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c3df1-8cc3-4105-8d6a-9612172b610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = GenericDataLoader(\n",
    "    X_train,\n",
    "    target_column = 'target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe8a0e-39f5-4896-a8e0-1aa3dee8f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_generate_syn_tab_sjppds():\n",
    "    syn_model = Plugins().get('syn_tab_sjppds',\n",
    "                              num_variables = list(range(9)),\n",
    "                              cat_variables = None,\n",
    "                              n_levels = 200,\n",
    "                              n_prop = 0.5)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_bayesnet():\n",
    "    syn_model = Plugins().get('bayesian_network',\n",
    "                          struct_learning_search_method = 'hillclimb',\n",
    "                          struct_learning_score = 'bic')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "    \n",
    "\n",
    "def train_and_generate_arf():\n",
    "    syn_model = Plugins().get('arf',\n",
    "                          num_trees = 70,\n",
    "                          delta = 0,\n",
    "                          max_iters = 2,\n",
    "                          early_stop = True,\n",
    "                          min_node_size = 6)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ddpm():\n",
    "    syn_model = Plugins().get('ddpm',\n",
    "                          n_iter = 8300,\n",
    "                          lr = 0.009824330156648882,\n",
    "                          batch_size = 3177,\n",
    "                          num_timesteps = 200,\n",
    "                          is_classification = False)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_tvae():\n",
    "    syn_model = Plugins().get('tvae',\n",
    "                          n_iter = 200,\n",
    "                          lr = 0.001,\n",
    "                          decoder_n_layers_hidden = 4,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 512,\n",
    "                          n_units_embedding = 150,\n",
    "                          decoder_n_units_hidden = 300,\n",
    "                          decoder_nonlin = \"leaky_relu\",\n",
    "                          decoder_dropout = 0.13648576055463643,\n",
    "                          encoder_n_layers_hidden = 2,\n",
    "                          encoder_n_units_hidden = 400,\n",
    "                          encoder_nonlin = \"tanh\",\n",
    "                          encoder_dropout = 0.02705334756273372)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ctgan():\n",
    "    syn_model = Plugins().get('ctgan',\n",
    "                          generator_n_layers_hidden = 1,\n",
    "                          generator_n_units_hidden = 150,\n",
    "                          generator_nonlin = 'relu',\n",
    "                          n_iter = 600,\n",
    "                          generator_dropout = 0.16863490048383495,\n",
    "                          discriminator_n_layers_hidden = 3,\n",
    "                          discriminator_n_units_hidden = 150,\n",
    "                          discriminator_nonlin = 'relu',\n",
    "                          discriminator_n_iter = 4,\n",
    "                          discriminator_dropout = 0.06303278452420555,\n",
    "                          lr = 0.0002,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 200,\n",
    "                          encoder_max_clusters = 5)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b4cb8a-8454-445f-bd12-102a341e20f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_california_syn_tab_sjppds = timeit.timeit(train_and_generate_syn_tab_sjppds, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_california_syn_tab_sjppds / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b74603c-3db0-4201-b684-fddadac64590",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_california_bayesnet = timeit.timeit(train_and_generate_bayesnet, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_california_bayesnet / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d4ecd-1682-47c0-8469-9d60f13d4497",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_california_arf = timeit.timeit(train_and_generate_arf, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_california_arf / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7696b6e-83a4-440a-9195-ca3b1d25c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_california_ddpm = timeit.timeit(train_and_generate_ddpm, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_california_ddpm / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc5112-a806-4318-abbb-3f72729804c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_california_tvae = timeit.timeit(train_and_generate_tvae, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_california_tvae / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24cacef-3c0e-4fcf-bda3-e3e959018f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_california_ctgan = timeit.timeit(train_and_generate_ctgan, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_california_ctgan / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c14b9-2c60-473c-8428-e0f367511065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "\n",
    "## mushroom data\n",
    "dataset = openml.datasets.get_dataset(24) \n",
    "\n",
    "X, y, _, attribute_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "X['target'] = y\n",
    "\n",
    "X = X.drop(X.columns[[10, 15]], axis=1) # column 10 has too many NAs and column 15 has no variability\n",
    "\n",
    "num_idx = None\n",
    "cat_idx = list(range(21))\n",
    "\n",
    "X = enforce_dtypes(dat = X, \n",
    "                   num_variables = num_idx, \n",
    "                   cat_variables = cat_idx)\n",
    "\n",
    "# Split the data\n",
    "aux = train_test_data_split(X, my_seed=123)\n",
    "\n",
    "X_train = aux[\"X_train\"]\n",
    "X_test = aux[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa66a4-fd80-4d11-a9c2-ab49e1a9ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = GenericDataLoader(\n",
    "    X_train,\n",
    "    target_column = 'target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d11e7-05af-45c2-8de9-f8117d0e84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_generate_syn_tab_sjppds():\n",
    "    syn_model = Plugins().get('syn_tab_sjppds',\n",
    "                              num_variables = None,\n",
    "                              cat_variables = list(range(21)),\n",
    "                              n_levels = 40,\n",
    "                              n_prop = 0.5)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_bayesnet():\n",
    "    syn_model = Plugins().get('bayesian_network',\n",
    "                          struct_learning_search_method = 'hillclimb',\n",
    "                          struct_learning_score = 'bic')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "    \n",
    "\n",
    "def train_and_generate_arf():\n",
    "    syn_model = Plugins().get('arf',\n",
    "                         num_trees = 100,\n",
    "                          delta = 0,\n",
    "                          max_iters = 1,\n",
    "                          early_stop = False,\n",
    "                          min_node_size = 2)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ddpm():\n",
    "    syn_model = Plugins().get('ddpm',\n",
    "                          n_iter = 5127,\n",
    "                          lr = 0.00884671824119367,\n",
    "                          batch_size = 4093,\n",
    "                          num_timesteps = 853,\n",
    "                          is_classification = True)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_tvae():\n",
    "    syn_model = Plugins().get('tvae',\n",
    "                          n_iter = 200,\n",
    "                          lr = 0.001,\n",
    "                          decoder_n_layers_hidden = 5,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 512,\n",
    "                          n_units_embedding = 150,\n",
    "                          decoder_n_units_hidden = 150,\n",
    "                          decoder_nonlin = 'relu',\n",
    "                          decoder_dropout = 0.1171471896118231,\n",
    "                          encoder_n_layers_hidden = 4,\n",
    "                          encoder_n_units_hidden = 300,\n",
    "                          encoder_nonlin = 'tanh',\n",
    "                          encoder_dropout = 0.16007215982462047)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ctgan():\n",
    "    syn_model = Plugins().get('ctgan',\n",
    "                          generator_n_layers_hidden = 4,\n",
    "                          generator_n_units_hidden = 50,\n",
    "                          generator_nonlin = 'leaky_relu',\n",
    "                          n_iter = 700,\n",
    "                          generator_dropout = 0.020973543252274986,\n",
    "                          discriminator_n_layers_hidden = 3,\n",
    "                          discriminator_n_units_hidden = 150,\n",
    "                          discriminator_nonlin = 'tanh',\n",
    "                          discriminator_n_iter = 4,\n",
    "                          discriminator_dropout = 0.1644064126493125,\n",
    "                          lr = 0.001,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 500,\n",
    "                          encoder_max_clusters = 13)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c6c31-ae96-44be-a179-b01db275808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_mushroom_syn_tab_sjppds = timeit.timeit(train_and_generate_syn_tab_sjppds, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_mushroom_syn_tab_sjppds / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef8c7c-ee25-4760-bd4a-bfa09e9b7da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_mushroom_bayesnet = timeit.timeit(train_and_generate_bayesnet, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_mushroom_bayesnet / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4effe8-f749-443a-a9fc-d1bcc43ba282",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_mushroom_arf = timeit.timeit(train_and_generate_arf, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_mushroom_arf / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f947801a-0d25-45e9-a69f-0886f885e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_mushroom_ddpm = timeit.timeit(train_and_generate_ddpm, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_mushroom_ddpm / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f709de8-cd85-4238-be23-c344096d1568",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_mushroom_tvae = timeit.timeit(train_and_generate_tvae, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_mushroom_tvae / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d213eae-52d4-48e4-a078-240cb7deff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_mushroom_ctgan = timeit.timeit(train_and_generate_ctgan, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_mushroom_ctgan / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8983e8-3c04-4ab2-be27-6136f703d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult dataset\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "openml_data = fetch_openml(name=\"adult\", as_frame=True, version=1)\n",
    "\n",
    "# Get the features and target as DataFrames\n",
    "X = openml_data.data  # Features (pandas DataFrame)\n",
    "y = openml_data.target  # Target (pandas Series)\n",
    "\n",
    "X[\"target\"] = y\n",
    "\n",
    "X = X.dropna()\n",
    "\n",
    "X = process_adult_data(X)\n",
    "\n",
    "num_idx = [2, 4]\n",
    "cat_idx = [0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "X = enforce_dtypes(dat = X, \n",
    "                   num_variables = num_idx, \n",
    "                   cat_variables = cat_idx)\n",
    "\n",
    "# Split the data\n",
    "aux = train_test_data_split(X, my_seed=123)\n",
    "\n",
    "X_train = aux[\"X_train\"]\n",
    "X_test = aux[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dece3e-8604-423f-ad73-7dce0966bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = GenericDataLoader(\n",
    "    X_train,\n",
    "    target_column = 'target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe11e6aa-c424-4bb4-a594-2d7bced2fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_generate_syn_tab_sjppds():\n",
    "    syn_model = Plugins().get('syn_tab_sjppds',\n",
    "                              num_variables = [2, 4],\n",
    "                              cat_variables = [0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "                              n_levels = 20,\n",
    "                              n_prop = 0.5)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_bayesnet():\n",
    "    syn_model = Plugins().get('bayesian_network',\n",
    "                          struct_learning_search_method = 'hillclimb',\n",
    "                          struct_learning_score = 'bic')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "    \n",
    "\n",
    "def train_and_generate_arf():\n",
    "    syn_model = Plugins().get('arf')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ddpm():\n",
    "    syn_model = Plugins().get(\"ddpm\",\n",
    "                          n_iter = 1051,\n",
    "                          lr = 0.0009375080542687667,\n",
    "                          batch_size = 2929,\n",
    "                          num_timesteps = 998,\n",
    "                          is_classification = True)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_tvae():\n",
    "    syn_model = Plugins().get(\"tvae\",\n",
    "                          n_iter = 300,\n",
    "                          lr = 0.0002,\n",
    "                          decoder_n_layers_hidden = 4,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 256,\n",
    "                          n_units_embedding = 200,\n",
    "                          decoder_n_units_hidden = 300,\n",
    "                          decoder_nonlin = \"elu\",\n",
    "                          decoder_dropout = 0.194325119117226,\n",
    "                          encoder_n_layers_hidden = 1,\n",
    "                          encoder_n_units_hidden = 450,\n",
    "                          encoder_nonlin = \"leaky_relu\",\n",
    "                          encoder_dropout = 0.04288563703094718)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ctgan():\n",
    "    syn_model = Plugins().get(\"ctgan\",\n",
    "                            n_iter = 1000,\n",
    "                            generator_n_layers_hidden = 2,\n",
    "                            generator_n_units_hidden = 50,\n",
    "                            generator_nonlin = \"tanh\",\n",
    "                            generator_dropout = 0.0575,\n",
    "                            discriminator_n_layers_hidden = 4,\n",
    "                            discriminator_n_units_hidden = 150,\n",
    "                            discriminator_nonlin = \"relu\")\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc3289-b97e-4358-959f-573b2be4ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_adult_syn_tab_sjppds = timeit.timeit(train_and_generate_syn_tab_sjppds, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_adult_syn_tab_sjppds / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475b708-d405-4170-9a83-bf6aae34effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_adult_bayesnet = timeit.timeit(train_and_generate_bayesnet, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_adult_bayesnet / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d053b30-ac76-4dde-b28d-5d10d5f082de",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_adult_arf = timeit.timeit(train_and_generate_arf, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_adult_arf / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0265777-03d7-4cb9-b0bb-057fc7d5788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_adult_ddpm = timeit.timeit(train_and_generate_ddpm, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_adult_ddpm / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6cef86-4546-4a30-839e-9da1b263d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_adult_tvae = timeit.timeit(train_and_generate_tvae, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_adult_tvae / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b3de0-d28a-4db0-8d72-402cb5df82c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_adult_ctgan = timeit.timeit(train_and_generate_ctgan, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_adult_ctgan / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c251919e-4ab7-4c36-b878-1ef60634fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select tuning parameter for eye movements data\n",
    "\n",
    "import openml\n",
    "\n",
    "# eye movements\n",
    "dataset = openml.datasets.get_dataset(44130) \n",
    "\n",
    "X, y, _, attribute_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "X['target'] = y\n",
    "\n",
    "num_idx = list(range(0, 20))\n",
    "cat_idx = [20]\n",
    "\n",
    "X = enforce_dtypes(dat = X, \n",
    "                   num_variables = num_idx, \n",
    "                   cat_variables = cat_idx)\n",
    "\n",
    "# Split the data\n",
    "aux = train_test_data_split(X, my_seed=123)\n",
    "\n",
    "X_train = aux[\"X_train\"]\n",
    "X_test = aux[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73762d7c-df87-438f-9ed2-dc2628cac0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = GenericDataLoader(\n",
    "    X_train,\n",
    "    target_column = 'target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45012e6-ab09-46aa-b64b-d2f5e93ff2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_generate_syn_tab_sjppds():\n",
    "    syn_model = Plugins().get('syn_tab_sjppds',\n",
    "                              num_variables = list(range(0, 20)),\n",
    "                              cat_variables = [20],\n",
    "                              n_levels = 20,\n",
    "                              n_prop = 0.5)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_bayesnet():\n",
    "    syn_model = Plugins().get('bayesian_network',\n",
    "                          struct_learning_search_method = 'hillclimb',\n",
    "                          struct_learning_score = 'bic')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "    \n",
    "\n",
    "def train_and_generate_arf():\n",
    "    syn_model = Plugins().get('arf')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ddpm():\n",
    "    syn_model = Plugins().get(\"ddpm\",\n",
    "                          n_iter = 1051,\n",
    "                          lr = 0.0009375080542687667,\n",
    "                          batch_size = 2929,\n",
    "                          num_timesteps = 998,\n",
    "                          is_classification = True)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_tvae():\n",
    "    syn_model = Plugins().get(\"tvae\",\n",
    "                          n_iter = 300,\n",
    "                          lr = 0.0002,\n",
    "                          decoder_n_layers_hidden = 4,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 256,\n",
    "                          n_units_embedding = 200,\n",
    "                          decoder_n_units_hidden = 300,\n",
    "                          decoder_nonlin = \"elu\",\n",
    "                          decoder_dropout = 0.194325119117226,\n",
    "                          encoder_n_layers_hidden = 1,\n",
    "                          encoder_n_units_hidden = 450,\n",
    "                          encoder_nonlin = \"leaky_relu\",\n",
    "                          encoder_dropout = 0.04288563703094718)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ctgan():\n",
    "    syn_model = Plugins().get(\"ctgan\",\n",
    "                            n_iter = 1000,\n",
    "                            generator_n_layers_hidden = 2,\n",
    "                            generator_n_units_hidden = 50,\n",
    "                            generator_nonlin = \"tanh\",\n",
    "                            generator_dropout = 0.0575,\n",
    "                            discriminator_n_layers_hidden = 4,\n",
    "                            discriminator_n_units_hidden = 150,\n",
    "                            discriminator_nonlin = \"relu\")\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e690c-dfd6-4ac1-b2ec-764ba7e8fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_eye_syn_tab_sjppds = timeit.timeit(train_and_generate_syn_tab_sjppds, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_eye_syn_tab_sjppds / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ad16ac-1443-4ddd-b4f8-17a1189ea9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_eye_bayesnet = timeit.timeit(train_and_generate_bayesnet, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_eye_ / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef205a6-71a1-47ff-b15b-32797952b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_eye_arf = timeit.timeit(train_and_generate_arf, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_eye_arf / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9355d9-bd18-470a-9b07-8fff16fd3d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_eye_ddpm = timeit.timeit(train_and_generate_ddpm, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_eye_ddpm / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a4bbf7-18b0-4a30-805e-915fd854190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_eye_tvae = timeit.timeit(train_and_generate_tvae, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_eye_tvae / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e714f01-0b81-443e-a664-8f21a9b20501",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_eye_ctgan = timeit.timeit(train_and_generate_ctgan, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_eye_ctgan / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19707117-c18b-4c98-8139-9c36114e7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_repli = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0fc33-6cfa-407a-bb87-f43aa752f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "\n",
    "# credit\n",
    "dataset = openml.datasets.get_dataset(44089) \n",
    "\n",
    "X, y, _, attribute_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "X['target'] = y\n",
    "\n",
    "num_idx = list(range(0, 10))\n",
    "cat_idx = [10]\n",
    "\n",
    "X = enforce_dtypes(dat = X, \n",
    "                   num_variables = num_idx, \n",
    "                   cat_variables = cat_idx)\n",
    "\n",
    "# Split the data\n",
    "aux = train_test_data_split(X, my_seed=123)\n",
    "\n",
    "X_train = aux[\"X_train\"]\n",
    "X_test = aux[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7812889-92ac-41e5-a452-1c914e427939",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = GenericDataLoader(\n",
    "    X_train,\n",
    "    target_column = 'target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd9cb9-b732-42bb-81be-945dec4274c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_generate_syn_tab_sjppds():\n",
    "    syn_model = Plugins().get('syn_tab_sjppds',\n",
    "                              num_variables = list(range(0, 10)),\n",
    "                              cat_variables = [10],\n",
    "                              n_levels = 1000,\n",
    "                              n_prop = 0.5)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_bayesnet():\n",
    "    syn_model = Plugins().get('bayesian_network',\n",
    "                          struct_learning_search_method = 'hillclimb',\n",
    "                          struct_learning_score = 'bic')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "    \n",
    "\n",
    "def train_and_generate_arf():\n",
    "    syn_model = Plugins().get('arf')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ddpm():\n",
    "    syn_model = Plugins().get(\"ddpm\",\n",
    "                          n_iter = 1051,\n",
    "                          lr = 0.0009375080542687667,\n",
    "                          batch_size = 2929,\n",
    "                          num_timesteps = 998,\n",
    "                          is_classification = True)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_tvae():\n",
    "    syn_model = Plugins().get(\"tvae\",\n",
    "                          n_iter = 300,\n",
    "                          lr = 0.0002,\n",
    "                          decoder_n_layers_hidden = 4,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 256,\n",
    "                          n_units_embedding = 200,\n",
    "                          decoder_n_units_hidden = 300,\n",
    "                          decoder_nonlin = \"elu\",\n",
    "                          decoder_dropout = 0.194325119117226,\n",
    "                          encoder_n_layers_hidden = 1,\n",
    "                          encoder_n_units_hidden = 450,\n",
    "                          encoder_nonlin = \"leaky_relu\",\n",
    "                          encoder_dropout = 0.04288563703094718)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ctgan():\n",
    "    syn_model = Plugins().get(\"ctgan\",\n",
    "                            n_iter = 1000,\n",
    "                            generator_n_layers_hidden = 2,\n",
    "                            generator_n_units_hidden = 50,\n",
    "                            generator_nonlin = \"tanh\",\n",
    "                            generator_dropout = 0.0575,\n",
    "                            discriminator_n_layers_hidden = 4,\n",
    "                            discriminator_n_units_hidden = 150,\n",
    "                            discriminator_nonlin = \"relu\")\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c331fa1c-8f9d-46cf-9a86-7c64dfe397c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_credit_syn_tab_sjppds = timeit.timeit(train_and_generate_syn_tab_sjppds, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_credit_syn_tab_sjppds / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d5da9-a255-4f54-907d-107297278701",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_credit_bayesnet = timeit.timeit(train_and_generate_bayesnet, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_credit_bayesnet / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8e5429-1b11-4f14-99f4-de24a3533014",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_credit_arf = timeit.timeit(train_and_generate_arf, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_credit_arf / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8542cc-8c87-48dd-814c-3a37f69ea19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_credit_ddpm = timeit.timeit(train_and_generate_ddpm, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_credit_ddpm / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf661b50-a0e3-4be0-b1e9-6486f708236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_credit_tvae = timeit.timeit(train_and_generate_tvae, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_credit_tvae / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c744b57d-a254-4aa7-9d36-9faa37f4054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_credit_ctgan = timeit.timeit(train_and_generate_ctgan, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_credit_ctgan / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b9ddd-2b50-4d3d-a471-88f62a221f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pol dataset\n",
    "\n",
    "import openml\n",
    "\n",
    "# pol\n",
    "dataset = openml.datasets.get_dataset(44122) \n",
    "\n",
    "X, y, _, attribute_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "X['target'] = y\n",
    "\n",
    "num_idx = list(range(0, 26))\n",
    "cat_idx = [26]\n",
    "\n",
    "X = enforce_dtypes(dat = X, \n",
    "                   num_variables = num_idx, \n",
    "                   cat_variables = cat_idx)\n",
    "\n",
    "# Split the data\n",
    "aux = train_test_data_split(X, my_seed=123)\n",
    "\n",
    "X_train = aux[\"X_train\"]\n",
    "X_test = aux[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ee3c6d-7e30-4d4f-b230-064c07d2cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = GenericDataLoader(\n",
    "    X_train,\n",
    "    target_column = 'target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d8c8fd-1c35-44d2-af0b-9f64f08533b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_generate_syn_tab_sjppds():\n",
    "    syn_model = Plugins().get('syn_tab_sjppds',\n",
    "                              num_variables = list(range(0, 26)),\n",
    "                              cat_variables = [26],\n",
    "                              n_levels = 15,\n",
    "                              n_prop = 0.5)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_bayesnet():\n",
    "    syn_model = Plugins().get('bayesian_network',\n",
    "                          struct_learning_search_method = 'hillclimb',\n",
    "                          struct_learning_score = 'bic')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "    \n",
    "\n",
    "def train_and_generate_arf():\n",
    "    syn_model = Plugins().get('arf')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ddpm():\n",
    "    syn_model = Plugins().get(\"ddpm\",\n",
    "                          n_iter = 1051,\n",
    "                          lr = 0.0009375080542687667,\n",
    "                          batch_size = 2929,\n",
    "                          num_timesteps = 998,\n",
    "                          is_classification = True)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_tvae():\n",
    "    syn_model = Plugins().get(\"tvae\",\n",
    "                          n_iter = 300,\n",
    "                          lr = 0.0002,\n",
    "                          decoder_n_layers_hidden = 4,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 256,\n",
    "                          n_units_embedding = 200,\n",
    "                          decoder_n_units_hidden = 300,\n",
    "                          decoder_nonlin = \"elu\",\n",
    "                          decoder_dropout = 0.194325119117226,\n",
    "                          encoder_n_layers_hidden = 1,\n",
    "                          encoder_n_units_hidden = 450,\n",
    "                          encoder_nonlin = \"leaky_relu\",\n",
    "                          encoder_dropout = 0.04288563703094718)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ctgan():\n",
    "    syn_model = Plugins().get(\"ctgan\",\n",
    "                            n_iter = 1000,\n",
    "                            generator_n_layers_hidden = 2,\n",
    "                            generator_n_units_hidden = 50,\n",
    "                            generator_nonlin = \"tanh\",\n",
    "                            generator_dropout = 0.0575,\n",
    "                            discriminator_n_layers_hidden = 4,\n",
    "                            discriminator_n_units_hidden = 150,\n",
    "                            discriminator_nonlin = \"relu\")\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5409a0fa-2b8d-4254-ad31-aebf3c740824",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_pol_syn_tab_sjppds = timeit.timeit(train_and_generate_syn_tab_sjppds, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_pol_syn_tab_sjppds / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe97783-5757-4982-9712-a8c9905caf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_pol_bayesnet = timeit.timeit(train_and_generate_bayesnet, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_pol_bayesnet / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d67c3-7728-4c39-821a-c62b0daf9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_pol_arf = timeit.timeit(train_and_generate_arf, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_pol_arf / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ed7aa-7856-4cab-8f79-180ec5efd6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_pol_ddpm = timeit.timeit(train_and_generate_ddpm, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_pol_ddpm / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d287c7c-99c2-4c34-afa6-36df114a650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_pol_tvae = timeit.timeit(train_and_generate_tvae, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_pol_tvae / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dca007-a45a-4d76-a793-70c76ef07668",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_pol_ctgan = timeit.timeit(train_and_generate_ctgan, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_pol_ctgan / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dbbc1e-04f0-4d83-a498-db3e4a95c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "\n",
    "# house_16H\n",
    "dataset = openml.datasets.get_dataset(44123) \n",
    "\n",
    "X, y, _, attribute_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "X['target'] = y\n",
    "\n",
    "num_idx = list(range(0, 16))\n",
    "cat_idx = [16]\n",
    "\n",
    "X = enforce_dtypes(dat = X, \n",
    "                   num_variables = num_idx, \n",
    "                   cat_variables = cat_idx)\n",
    "\n",
    "# Split the data\n",
    "aux = train_test_data_split(X, my_seed=123)\n",
    "\n",
    "X_train = aux[\"X_train\"]\n",
    "X_test = aux[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e374dbe9-2279-4b91-97d0-846db4286e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = GenericDataLoader(\n",
    "    X_train,\n",
    "    target_column = 'target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e8a2a-3296-4f36-a07b-a4bdb0048954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_generate_syn_tab_sjppds():\n",
    "    syn_model = Plugins().get('syn_tab_sjppds',\n",
    "                              num_variables = list(range(0, 16)),\n",
    "                              cat_variables = [16],\n",
    "                              n_levels = 1000,\n",
    "                              n_prop = 0.5)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_bayesnet():\n",
    "    syn_model = Plugins().get('bayesian_network',\n",
    "                          struct_learning_search_method = 'hillclimb',\n",
    "                          struct_learning_score = 'bic')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "    \n",
    "\n",
    "def train_and_generate_arf():\n",
    "    syn_model = Plugins().get('arf')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ddpm():\n",
    "    syn_model = Plugins().get(\"ddpm\",\n",
    "                          n_iter = 1051,\n",
    "                          lr = 0.0009375080542687667,\n",
    "                          batch_size = 2929,\n",
    "                          num_timesteps = 998,\n",
    "                          is_classification = True)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_tvae():\n",
    "    syn_model = Plugins().get(\"tvae\",\n",
    "                          n_iter = 300,\n",
    "                          lr = 0.0002,\n",
    "                          decoder_n_layers_hidden = 4,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 256,\n",
    "                          n_units_embedding = 200,\n",
    "                          decoder_n_units_hidden = 300,\n",
    "                          decoder_nonlin = \"elu\",\n",
    "                          decoder_dropout = 0.194325119117226,\n",
    "                          encoder_n_layers_hidden = 1,\n",
    "                          encoder_n_units_hidden = 450,\n",
    "                          encoder_nonlin = \"leaky_relu\",\n",
    "                          encoder_dropout = 0.04288563703094718)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ctgan():\n",
    "    syn_model = Plugins().get(\"ctgan\",\n",
    "                            n_iter = 1000,\n",
    "                            generator_n_layers_hidden = 2,\n",
    "                            generator_n_units_hidden = 50,\n",
    "                            generator_nonlin = \"tanh\",\n",
    "                            generator_dropout = 0.0575,\n",
    "                            discriminator_n_layers_hidden = 4,\n",
    "                            discriminator_n_units_hidden = 150,\n",
    "                            discriminator_nonlin = \"relu\")\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca8c18a-06ae-412e-b6fa-d2d0fc871464",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_house16h_syn_tab_sjppds = timeit.timeit(train_and_generate_syn_tab_sjppds, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_house16h_syn_tab_sjppds / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e13a487-4fa9-47c5-9269-9e8f146ec330",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_house16h_bayesnet = timeit.timeit(train_and_generate_bayesnet, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_house16h_bayesnet / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71604ad3-4c02-4e50-9642-36e534195ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_house16h_arf = timeit.timeit(train_and_generate_arf, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_house16h_arf / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1fb4ce-ef3a-4476-9933-3e367757ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_house16h_ddpm = timeit.timeit(train_and_generate_ddpm, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_house16h_ddpm / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb7a8e-de44-4864-af21-44220b901e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_house16h_tvae = timeit.timeit(train_and_generate_tvae, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_house16h_tvae / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b599b-9d11-4a95-b962-735a03f95a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_house16h_ctgan = timeit.timeit(train_and_generate_ctgan, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_house16h_ctgan / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78695247-880c-46d1-9849-30bfdad4fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bank marketing\n",
    "\n",
    "import openml\n",
    "\n",
    "# bank marketing\n",
    "dataset = openml.datasets.get_dataset(44126) \n",
    "\n",
    "X, y, _, attribute_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "X['target'] = y\n",
    "\n",
    "num_idx = list(range(0, 7))\n",
    "cat_idx = [7]\n",
    "\n",
    "X = enforce_dtypes(dat = X, \n",
    "                   num_variables = num_idx, \n",
    "                   cat_variables = cat_idx)\n",
    "\n",
    "# Split the data\n",
    "aux = train_test_data_split(X, my_seed=123)\n",
    "\n",
    "X_train = aux[\"X_train\"]\n",
    "X_test = aux[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd4e96c-dedf-4200-80dc-2ac49b9d6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = GenericDataLoader(\n",
    "    X_train,\n",
    "    target_column = 'target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293ded6b-83e5-4c0a-80fb-84f9245cb266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_generate_syn_tab_sjppds():\n",
    "    syn_model = Plugins().get('syn_tab_sjppds',\n",
    "                              num_variables = list(range(0, 7)),\n",
    "                              cat_variables = [7],\n",
    "                              n_levels = 100,\n",
    "                              n_prop = 0.5)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_bayesnet():\n",
    "    syn_model = Plugins().get('bayesian_network',\n",
    "                          struct_learning_search_method = 'hillclimb',\n",
    "                          struct_learning_score = 'bic')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "    \n",
    "\n",
    "def train_and_generate_arf():\n",
    "    syn_model = Plugins().get('arf')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ddpm():\n",
    "    syn_model = Plugins().get(\"ddpm\",\n",
    "                          n_iter = 1051,\n",
    "                          lr = 0.0009375080542687667,\n",
    "                          batch_size = 2929,\n",
    "                          num_timesteps = 998,\n",
    "                          is_classification = True)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_tvae():\n",
    "    syn_model = Plugins().get(\"tvae\",\n",
    "                          n_iter = 300,\n",
    "                          lr = 0.0002,\n",
    "                          decoder_n_layers_hidden = 4,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 256,\n",
    "                          n_units_embedding = 200,\n",
    "                          decoder_n_units_hidden = 300,\n",
    "                          decoder_nonlin = \"elu\",\n",
    "                          decoder_dropout = 0.194325119117226,\n",
    "                          encoder_n_layers_hidden = 1,\n",
    "                          encoder_n_units_hidden = 450,\n",
    "                          encoder_nonlin = \"leaky_relu\",\n",
    "                          encoder_dropout = 0.04288563703094718)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ctgan():\n",
    "    syn_model = Plugins().get(\"ctgan\",\n",
    "                            n_iter = 1000,\n",
    "                            generator_n_layers_hidden = 2,\n",
    "                            generator_n_units_hidden = 50,\n",
    "                            generator_nonlin = \"tanh\",\n",
    "                            generator_dropout = 0.0575,\n",
    "                            discriminator_n_layers_hidden = 4,\n",
    "                            discriminator_n_units_hidden = 150,\n",
    "                            discriminator_nonlin = \"relu\")\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fde39d-b622-45e2-a7f0-ee729d7166bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_bankmark_syn_tab_sjppds = timeit.timeit(train_and_generate_syn_tab_sjppds, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_bankmark_syn_tab_sjppds / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c249e6-b028-4a6c-8206-8b050f95fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_bankmark_bayesnet = timeit.timeit(train_and_generate_bayesnet, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_bankmark_bayesnet / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dca52a-c126-4c2c-9984-993d1f450e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_bankmark_arf = timeit.timeit(train_and_generate_arf, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_bankmark_arf / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da779c0-4e30-4f7b-9cc7-e65ec4e5029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_bankmark_ddpm = timeit.timeit(train_and_generate_ddpm, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_bankmark_ddpm / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340cf5bc-d22f-44e9-9e60-c7e87dd04723",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_bankmark_tvae = timeit.timeit(train_and_generate_tvae, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_bankmark_tvae / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3245681-1144-489e-83a6-537d768ba650",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_bankmark_ctgan = timeit.timeit(train_and_generate_ctgan, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_bankmark_ctgan / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922c3270-1304-474d-8275-2c8cc275d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Fetch the Abalone dataset\n",
    "abalone = fetch_openml(name=\"abalone\", version=1, as_frame=True)\n",
    "\n",
    "# Access the data and target\n",
    "X = abalone.data\n",
    "y = abalone.target\n",
    "\n",
    "X['target'] =  y # Rings\n",
    "\n",
    "num_idx = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "cat_idx = [0]\n",
    "\n",
    "X = enforce_dtypes(dat = X, \n",
    "                   num_variables = num_idx, \n",
    "                   cat_variables = cat_idx)\n",
    "\n",
    "# Split the data\n",
    "aux = train_test_data_split(X, my_seed=123)\n",
    "\n",
    "X_train = aux[\"X_train\"]\n",
    "X_test = aux[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0d94ca-2341-4a21-b455-eae8e157fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = GenericDataLoader(\n",
    "    X_train,\n",
    "    target_column = 'target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41e4582-5873-4455-9213-08ec71352de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_generate_syn_tab_sjppds():\n",
    "    syn_model = Plugins().get('syn_tab_sjppds',\n",
    "                              num_variables = [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                              cat_variables = [0],\n",
    "                              n_levels = 20,\n",
    "                              n_prop = 0.5)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_bayesnet():\n",
    "    syn_model = Plugins().get('bayesian_network',\n",
    "                          struct_learning_search_method = 'hillclimb',\n",
    "                          struct_learning_score = 'bic')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "    \n",
    "\n",
    "def train_and_generate_arf():\n",
    "    syn_model = Plugins().get('arf',\n",
    "                              num_trees = 80,\n",
    "                              delta = 0,\n",
    "                              max_iters = 2,\n",
    "                              early_stop = False,\n",
    "                              min_node_size = 2)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ddpm():\n",
    "    syn_model = Plugins().get(\"ddpm\",\n",
    "                          n_iter = 7605,\n",
    "                          lr = 0.002991978123076162,\n",
    "                          batch_size = 970,\n",
    "                          num_timesteps = 407,\n",
    "                          is_classification = False)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_tvae():\n",
    "    syn_model = Plugins().get(\"tvae\",\n",
    "                              n_iter = 400,\n",
    "                              lr = 0.001,\n",
    "                              decoder_n_layers_hidden = 5,\n",
    "                              weight_decay = 0.0001,\n",
    "                              batch_size = 128,\n",
    "                              n_units_embedding = 200,\n",
    "                              decoder_n_units_hidden = 150,\n",
    "                              decoder_nonlin = 'tanh',\n",
    "                              decoder_dropout = 0.19964446358158816,\n",
    "                              encoder_n_layers_hidden = 4,\n",
    "                              encoder_n_units_hidden = 100,\n",
    "                              encoder_nonlin = 'relu',\n",
    "                              encoder_dropout = 0.0820245231222064)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ctgan():\n",
    "    syn_model = Plugins().get(\"ctgan\",\n",
    "                              generator_n_layers_hidden = 1,\n",
    "                              generator_n_units_hidden = 100,\n",
    "                              generator_nonlin = 'elu',\n",
    "                              n_iter = 700,\n",
    "                              generator_dropout = 0.13836424598477665,\n",
    "                              discriminator_n_layers_hidden = 2,\n",
    "                              discriminator_n_units_hidden = 100,\n",
    "                              discriminator_nonlin = 'tanh',\n",
    "                              discriminator_n_iter = 5,\n",
    "                              discriminator_dropout = 0.023861565936528797,\n",
    "                              lr = 0.001,\n",
    "                              weight_decay = 0.0001,\n",
    "                              batch_size = 200,\n",
    "                              encoder_max_clusters = 8)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b96cef-eced-4bb7-be56-ab9c0ace3c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_abalone_syn_tab_sjppds = timeit.timeit(train_and_generate_syn_tab_sjppds, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_abalone_syn_tab_sjppds / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccbe053-4c53-4a8d-801c-0b94ea4fa8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_abalone_bayesnet = timeit.timeit(train_and_generate_bayesnet, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_abalone_bayesnet / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d4ec3-2716-40a9-bbb8-707276e02a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_abalone_arf = timeit.timeit(train_and_generate_arf, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_abalone_arf / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf50b9-2bae-4249-a615-56361203a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_abalone_ddpm = timeit.timeit(train_and_generate_ddpm, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_abalone_ddpm / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f27047-7036-4d62-b6fa-8a5ee392e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_abalone_tvae = timeit.timeit(train_and_generate_tvae, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_abalone_tvae / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50716fd5-a8bb-45cd-99a7-aefc7aa194f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_abalone_ctgan = timeit.timeit(train_and_generate_ctgan, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_abalone_ctgan / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23741343-89eb-4c14-911a-037419235268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MagicTelescope dataset\n",
    "\n",
    "import openml\n",
    "\n",
    "# MagicTelescope\n",
    "dataset = openml.datasets.get_dataset(44125) \n",
    "\n",
    "X, y, _, attribute_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "X['target'] = y\n",
    "\n",
    "num_idx = list(range(0, 10))\n",
    "cat_idx = [10]\n",
    "\n",
    "X = enforce_dtypes(dat = X, \n",
    "                   num_variables = num_idx, \n",
    "                   cat_variables = cat_idx)\n",
    "\n",
    "# Split the data\n",
    "aux = train_test_data_split(X, my_seed=123)\n",
    "\n",
    "X_train = aux[\"X_train\"]\n",
    "X_test = aux[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba3cba6-2260-4991-ba9a-cc9f9d2f06f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = GenericDataLoader(\n",
    "    X_train,\n",
    "    target_column = 'target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6efc43-e19d-4e90-bab0-62fe79eddda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_generate_syn_tab_sjppds():\n",
    "    syn_model = Plugins().get('syn_tab_sjppds',\n",
    "                              num_variables = list(range(0, 10)),\n",
    "                              cat_variables = [10],\n",
    "                              n_levels = 25,\n",
    "                              n_prop = 0.5)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_bayesnet():\n",
    "    syn_model = Plugins().get('bayesian_network',\n",
    "                          struct_learning_search_method = 'hillclimb',\n",
    "                          struct_learning_score = 'bic')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "    \n",
    "\n",
    "def train_and_generate_arf():\n",
    "    syn_model = Plugins().get('arf')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ddpm():\n",
    "    syn_model = Plugins().get(\"ddpm\",\n",
    "                          n_iter = 1051,\n",
    "                          lr = 0.0009375080542687667,\n",
    "                          batch_size = 2929,\n",
    "                          num_timesteps = 998,\n",
    "                          is_classification = True)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_tvae():\n",
    "    syn_model = Plugins().get(\"tvae\",\n",
    "                          n_iter = 300,\n",
    "                          lr = 0.0002,\n",
    "                          decoder_n_layers_hidden = 4,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 256,\n",
    "                          n_units_embedding = 200,\n",
    "                          decoder_n_units_hidden = 300,\n",
    "                          decoder_nonlin = \"elu\",\n",
    "                          decoder_dropout = 0.194325119117226,\n",
    "                          encoder_n_layers_hidden = 1,\n",
    "                          encoder_n_units_hidden = 450,\n",
    "                          encoder_nonlin = \"leaky_relu\",\n",
    "                          encoder_dropout = 0.04288563703094718)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ctgan():\n",
    "    syn_model = Plugins().get(\"ctgan\",\n",
    "                            n_iter = 1000,\n",
    "                            generator_n_layers_hidden = 2,\n",
    "                            generator_n_units_hidden = 50,\n",
    "                            generator_nonlin = \"tanh\",\n",
    "                            generator_dropout = 0.0575,\n",
    "                            discriminator_n_layers_hidden = 4,\n",
    "                            discriminator_n_units_hidden = 150,\n",
    "                            discriminator_nonlin = \"relu\")\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b79adb2-0448-49a6-84d8-1298ba2ae20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_magtel_syn_tab_sjppds = timeit.timeit(train_and_generate_syn_tab_sjppds, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_magtel_syn_tab_sjppds / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4450533e-ec2e-49e4-afe6-a9206fb83028",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_magtel_bayesnet = timeit.timeit(train_and_generate_bayesnet, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_magtel_bayesnet / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6fe095-c682-4161-8de0-c5c6ac718bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_magtel_arf = timeit.timeit(train_and_generate_arf, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_magtel_arf / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ba4772-63a6-48be-9476-c3b84b1e17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_magtel_ddpm = timeit.timeit(train_and_generate_ddpm, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_magtel_ddpm / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b1488d-3a8d-48e5-aae0-7ecabc5b3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_magtel_tvae = timeit.timeit(train_and_generate_tvae, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_magtel_tvae / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc765172-c94d-469f-a3ea-3455f8b8fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_magtel_ctgan = timeit.timeit(train_and_generate_ctgan, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_magtel_ctgan / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d56a60-400b-4ff1-8c90-45767bfcef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the electricity data \n",
    "\n",
    "import openml\n",
    "\n",
    "# electricity\n",
    "dataset = openml.datasets.get_dataset(44120) \n",
    "\n",
    "X, y, _, attribute_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "X['target'] = y\n",
    "\n",
    "num_idx = list(range(0, 7))\n",
    "cat_idx = [7]\n",
    "\n",
    "X = enforce_dtypes(dat = X, \n",
    "                   num_variables = num_idx, \n",
    "                   cat_variables = cat_idx)\n",
    "\n",
    "# Split the data\n",
    "aux = train_test_data_split(X, my_seed=123)\n",
    "\n",
    "X_train = aux[\"X_train\"]\n",
    "X_test = aux[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276ce378-10bc-4209-bbe8-f98c240cc995",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = GenericDataLoader(\n",
    "    X_train,\n",
    "    target_column = 'target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c8765-b915-4b87-981a-c01ca1982f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_generate_syn_tab_sjppds():\n",
    "    syn_model = Plugins().get('syn_tab_sjppds',\n",
    "                              num_variables = list(range(0, 7)),\n",
    "                              cat_variables = [7],\n",
    "                              n_levels = 20,\n",
    "                              n_prop = 0.5)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_bayesnet():\n",
    "    syn_model = Plugins().get('bayesian_network',\n",
    "                          struct_learning_search_method = 'hillclimb',\n",
    "                          struct_learning_score = 'bic')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "    \n",
    "\n",
    "def train_and_generate_arf():\n",
    "    syn_model = Plugins().get('arf')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ddpm():\n",
    "    syn_model = Plugins().get(\"ddpm\",\n",
    "                          n_iter = 1051,\n",
    "                          lr = 0.0009375080542687667,\n",
    "                          batch_size = 2929,\n",
    "                          num_timesteps = 998,\n",
    "                          is_classification = True)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_tvae():\n",
    "    syn_model = Plugins().get(\"tvae\",\n",
    "                          n_iter = 300,\n",
    "                          lr = 0.0002,\n",
    "                          decoder_n_layers_hidden = 4,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 256,\n",
    "                          n_units_embedding = 200,\n",
    "                          decoder_n_units_hidden = 300,\n",
    "                          decoder_nonlin = \"elu\",\n",
    "                          decoder_dropout = 0.194325119117226,\n",
    "                          encoder_n_layers_hidden = 1,\n",
    "                          encoder_n_units_hidden = 450,\n",
    "                          encoder_nonlin = \"leaky_relu\",\n",
    "                          encoder_dropout = 0.04288563703094718)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ctgan():\n",
    "    syn_model = Plugins().get(\"ctgan\",\n",
    "                            n_iter = 1000,\n",
    "                            generator_n_layers_hidden = 2,\n",
    "                            generator_n_units_hidden = 50,\n",
    "                            generator_nonlin = \"tanh\",\n",
    "                            generator_dropout = 0.0575,\n",
    "                            discriminator_n_layers_hidden = 4,\n",
    "                            discriminator_n_units_hidden = 150,\n",
    "                            discriminator_nonlin = \"relu\")\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0140d187-b477-4038-a61e-7d40d59ecd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_electricity_syn_tab_sjppds = timeit.timeit(train_and_generate_syn_tab_sjppds, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_electricity_syn_tab_sjppds / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65be6e96-6956-4bda-b30d-aabf226d42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_electricity_bayesnet = timeit.timeit(train_and_generate_bayesnet, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_electricity_bayesnet / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc68b12-3cbf-4446-821d-60afe432281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_electricity_arf = timeit.timeit(train_and_generate_arf, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_electricity_arf / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0506c604-7445-43d9-85b3-e26b064cbf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_electricity_ddpm = timeit.timeit(train_and_generate_ddpm, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_electricity_ddpm / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ec4e3-2cdd-4358-8c99-d621565f7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_electricity_tvae = timeit.timeit(train_and_generate_tvae, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_electricity_tvae / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248e5b82-edf8-45d4-94da-35513e1e37ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_electricity_ctgan = timeit.timeit(train_and_generate_ctgan, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_electricity_ctgan / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87468daf-922a-4405-9214-9dbbcedc1cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "\n",
    "# Diabetes130US\n",
    "dataset = openml.datasets.get_dataset(45022) \n",
    "\n",
    "X, y, _, attribute_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "X['target'] = y\n",
    "\n",
    "num_idx = list(range(0, 7))\n",
    "cat_idx = [7]\n",
    "\n",
    "X = enforce_dtypes(dat = X, \n",
    "                   num_variables = num_idx, \n",
    "                   cat_variables = cat_idx)\n",
    "\n",
    "# Split the data\n",
    "aux = train_test_data_split(X, my_seed=123)\n",
    "\n",
    "X_train = aux[\"X_train\"]\n",
    "X_test = aux[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e87b9-a873-4c0c-8926-85c8ec8b9be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = GenericDataLoader(\n",
    "    X_train,\n",
    "    target_column = 'target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8948b5-9d6c-40b9-84ed-2eabf5e7174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_generate_syn_tab_sjppds():\n",
    "    syn_model = Plugins().get('syn_tab_sjppds',\n",
    "                              num_variables = list(range(0, 7)),\n",
    "                              cat_variables = [7],\n",
    "                              n_levels = 35,\n",
    "                              n_prop = 0.5)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_bayesnet():\n",
    "    syn_model = Plugins().get('bayesian_network',\n",
    "                          struct_learning_search_method = 'hillclimb',\n",
    "                          struct_learning_score = 'bic')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "    \n",
    "\n",
    "def train_and_generate_arf():\n",
    "    syn_model = Plugins().get('arf')\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ddpm():\n",
    "    syn_model = Plugins().get(\"ddpm\",\n",
    "                          n_iter = 1051,\n",
    "                          lr = 0.0009375080542687667,\n",
    "                          batch_size = 2929,\n",
    "                          num_timesteps = 998,\n",
    "                          is_classification = True)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_tvae():\n",
    "    syn_model = Plugins().get(\"tvae\",\n",
    "                          n_iter = 300,\n",
    "                          lr = 0.0002,\n",
    "                          decoder_n_layers_hidden = 4,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 256,\n",
    "                          n_units_embedding = 200,\n",
    "                          decoder_n_units_hidden = 300,\n",
    "                          decoder_nonlin = \"elu\",\n",
    "                          decoder_dropout = 0.194325119117226,\n",
    "                          encoder_n_layers_hidden = 1,\n",
    "                          encoder_n_units_hidden = 450,\n",
    "                          encoder_nonlin = \"leaky_relu\",\n",
    "                          encoder_dropout = 0.04288563703094718)\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def train_and_generate_ctgan():\n",
    "    syn_model = Plugins().get(\"ctgan\",\n",
    "                            n_iter = 1000,\n",
    "                            generator_n_layers_hidden = 2,\n",
    "                            generator_n_units_hidden = 50,\n",
    "                            generator_nonlin = \"tanh\",\n",
    "                            generator_dropout = 0.0575,\n",
    "                            discriminator_n_layers_hidden = 4,\n",
    "                            discriminator_n_units_hidden = 150,\n",
    "                            discriminator_nonlin = \"relu\")\n",
    "    n = len(loader_train)\n",
    "    syn_model.fit(loader_train)\n",
    "    Y = syn_model.generate(count=n).dataframe()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf1781-c86c-4720-bcba-53ec86aebbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_diabetes130us_syn_tab_sjppds = timeit.timeit(train_and_generate_syn_tab_sjppds, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_diabetes130us_syn_tab_sjppds / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297113d-aee7-45d4-99df-8a623292798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_diabetes130us_bayesnet = timeit.timeit(train_and_generate_bayesnet, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_diabetes130us_bayesnet / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc89dff-bf45-4d2c-80b3-5fb0bd6ddf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_diabetes130us_arf = timeit.timeit(train_and_generate_arf, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_diabetes130us_arf / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f085a-0fd1-4aa8-884f-1571eb17cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_diabetes130us_ddpm = timeit.timeit(train_and_generate_ddpm, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_diabetes130us_ddpm / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e481497-0c27-47a5-831f-451378f28c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_diabetes130us_tvae = timeit.timeit(train_and_generate_tvae, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_diabetes130us_tvae / num_repli:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a4a5b-dbfc-4272-902d-2a6fa1645828",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_diabetes130us_ctgan = timeit.timeit(train_and_generate_ctgan, number=num_repli)  # Repeat num_repli times\n",
    "print(f\"Average execution time: {rt_diabetes130us_ctgan / num_repli:.6f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
