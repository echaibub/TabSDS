{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e15e64-c4fa-4438-a7c7-5c7fa1d05e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install synthcity\n",
    "!pip uninstall -y torchaudio torchdata\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc8ffb-5f6c-4d8b-a088-efff77abb660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# third party\n",
    "import optuna\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# synthcity absolute\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
    "\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae156ba-4375-44f4-99f0-0e07c1c4c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function for the optuna optmization\n",
    "# we optmize for minimizing detection of synthetic vs real data\n",
    "\n",
    "from synthcity.utils.optuna_sample import suggest_all\n",
    "from synthcity.benchmark import Benchmarks\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    hp_space = Plugins().get(PLUGIN).hyperparameter_space()\n",
    "    params = suggest_all(trial, hp_space)\n",
    "    if PLUGIN == \"ddpm\":\n",
    "        params[\"is_classification\"] = False\n",
    "    ID = f\"trial_{trial.number}\"\n",
    "    try:\n",
    "        report = Benchmarks.evaluate(\n",
    "            [(ID, PLUGIN, params)],\n",
    "            train_loader,\n",
    "            repeats=1,\n",
    "            metrics={\"detection\": [\"detection_xgb\"]}, \n",
    "        )\n",
    "    except Exception as e:  # invalid set of params\n",
    "        print(f\"{type(e).__name__}: {e}\")\n",
    "        print(params)\n",
    "        raise optuna.TrialPruned()\n",
    "    score = report[ID].query('direction == \"minimize\"')['mean'].mean()\n",
    "    # average score across all metrics with direction=\"minimize\"\n",
    "    return score\n",
    "\n",
    "\n",
    "def enforce_dtypes(dat, \n",
    "                   num_variables, \n",
    "                   cat_variables):\n",
    "    \"\"\"\n",
    "    Enforce \"float64\" type for numeric variables and \"object\" type for the\n",
    "    categorical variables\n",
    "    Parameters:\n",
    "        dat (pd.DataFrame): Input data matrix (numeric, categorical, or mixed).\n",
    "        num_variables (list): Indices of numeric variables.\n",
    "        cat_variables (list): Indices of categorical variables.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: with transformed data types\n",
    "    \"\"\"\n",
    "    if num_variables is not None and cat_variables is None:\n",
    "        dat_N = pd.DataFrame(dat.iloc[:, num_variables], dtype = \"float64\")\n",
    "        dat = dat_N\n",
    "\n",
    "    elif num_variables is None and cat_variables is not None:\n",
    "        dat_C = pd.DataFrame(dat.iloc[:, cat_variables], dtype = \"str\")\n",
    "        dat = dat_C\n",
    "\n",
    "    elif num_variables is not None and cat_variables is not None:\n",
    "        dat_N = pd.DataFrame(dat.iloc[:, num_variables], dtype = \"float64\")\n",
    "        dat_C = pd.DataFrame(dat.iloc[:, cat_variables], dtype = \"str\")\n",
    "        dat = pd.concat([dat_N, dat_C], axis=1)\n",
    "        # Reorder columns to match the order in the original data\n",
    "        reordered_indices = num_variables + cat_variables\n",
    "        dat = dat.iloc[:, np.argsort(reordered_indices)]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"At least one of num_variables or cat_variables must be specified.\")\n",
    "    \n",
    "    return dat \n",
    "\n",
    "\n",
    "def train_test_data_split(X, my_seed):\n",
    "    \"\"\"\n",
    "    Splits the data X into training and testing sets, using a random seed.\n",
    "    \n",
    "    Parameters:\n",
    "    X (pd.DataFrame): The input data DataFrame.\n",
    "    my_seed (int): The random seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing the training and testing DataFrames.\n",
    "          {'X_train': X_train, 'X_test': X_test}\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    np.random.seed(my_seed)\n",
    "    \n",
    "    # Get the total number of rows\n",
    "    n = X.shape[0]\n",
    "    n_sub = n // 2  # Floor division to get half the rows\n",
    "    \n",
    "    # Randomly sample indexes for the training set\n",
    "    idx_train = np.random.choice(X.index, size=n_sub, replace=False)\n",
    "    \n",
    "    # Compute the test indexes as the set difference\n",
    "    idx_test = X.index.difference(idx_train)\n",
    "\n",
    "    # Adjust sizes to make them equal if necessary\n",
    "    if len(idx_train) < len(idx_test):\n",
    "        idx_test = idx_test[:-1]  # Remove the last test index\n",
    "    \n",
    "    # Split the data\n",
    "    X_train = X.loc[idx_train]\n",
    "    X_test = X.loc[idx_test]\n",
    "    \n",
    "    return {\"X_train\": X_train, \"X_test\": X_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6f0f73-b437-42b5-9e7b-a8c0b8dd463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Fetch the Abalone dataset\n",
    "abalone = fetch_openml(name=\"abalone\", version=1, as_frame=True)\n",
    "\n",
    "# Access the data and target\n",
    "X = abalone.data\n",
    "y = abalone.target\n",
    "\n",
    "X['target'] =  y # Rings\n",
    "\n",
    "num_idx = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "cat_idx = [0]\n",
    "\n",
    "X = enforce_dtypes(dat = X, \n",
    "                   num_variables = num_idx, \n",
    "                   cat_variables = cat_idx)\n",
    "\n",
    "# Split the data\n",
    "aux = train_test_data_split(X, my_seed=123)\n",
    "\n",
    "X_train = aux[\"X_train\"]\n",
    "X_test = aux[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae7e82-2b66-4efb-817a-78a143cb538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader\n",
    "\n",
    "train_loader = GenericDataLoader(\n",
    "    X_train,\n",
    "    target_column=\"target\",\n",
    ")\n",
    "\n",
    "test_loader = GenericDataLoader(\n",
    "    X_test,\n",
    "    target_column=\"target\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b93e1ad-b6be-4a51-b0d2-e5b5f46e7897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of optuna trials\n",
    "\n",
    "n_trials = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23145939-b901-466d-bc22-8d5407180dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run optuna for ddpm\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "PLUGIN = \"ddpm\"\n",
    "plugin_cls = type(Plugins().get(PLUGIN))\n",
    "\n",
    "study_ddpm = optuna.create_study(direction=\"minimize\")\n",
    "study_ddpm.optimize(objective, n_trials=n_trials)\n",
    "study_ddpm.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6969c1-a66f-4423-9bf2-2e5209ef86ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "PLUGIN = \"arf\"\n",
    "plugin_cls = type(Plugins().get(PLUGIN))\n",
    "\n",
    "study_arf = optuna.create_study(direction=\"minimize\")\n",
    "study_arf.optimize(objective, n_trials=n_trials)\n",
    "study_arf.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b6250-065c-4ca0-aa86-78ed18632134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run optuna for tvae\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "PLUGIN = \"tvae\"\n",
    "plugin_cls = type(Plugins().get(PLUGIN))\n",
    "\n",
    "study_tvae = optuna.create_study(direction=\"minimize\")\n",
    "study_tvae.optimize(objective, n_trials=n_trials)\n",
    "study_tvae.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15d32d-6d4e-48ac-a107-b1281c2ca3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run optuna for ctgan\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "PLUGIN = \"ctgan\"\n",
    "plugin_cls = type(Plugins().get(PLUGIN))\n",
    "\n",
    "study_ctgan = optuna.create_study(direction=\"minimize\")\n",
    "study_ctgan.optimize(objective, n_trials=n_trials)\n",
    "study_ctgan.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
