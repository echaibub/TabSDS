{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e668040c-3380-4662-9662-28ab9b2ad474",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install synthcity\n",
    "!pip uninstall -y torchaudio torchdata\n",
    "!pip install openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456be32a-ea01-4ff8-a33b-541911855282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source code\n",
    "\n",
    "import os\n",
    "\n",
    "code_path = 'code/'\n",
    "\n",
    "# source utility functions \n",
    "file_path = os.path.join(code_path, 'utility_functions_syn_tab_sjppds_for_icml_2025.py')\n",
    "with open(os.path.expanduser(file_path)) as file:\n",
    "    exec(file.read())\n",
    "\n",
    "# source additional utility functions \n",
    "file_path = os.path.join(code_path, 'utility_functions_additional_for_icml_2025.py')\n",
    "with open(os.path.expanduser(file_path)) as file:\n",
    "    exec(file.read())\n",
    "\n",
    "# source the synth_tab_sjppds method synthcity plugin\n",
    "file_path = os.path.join(code_path, 'syn_tab_sjppds_synthcity_plugin_for_icml_2025.py')\n",
    "with open(os.path.expanduser(file_path)) as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e891f671-f9ec-4392-9d2c-e8ed2135658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthcity absolute\n",
    "from synthcity.plugins import Plugins\n",
    "\n",
    "generators = Plugins()\n",
    "\n",
    "generators.add(\"syn_tab_sjppds\", SynTabSjppdsPlugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50ec35-d469-4378-8399-b25bcb7f9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "\n",
    "## mushroom data\n",
    "dataset = openml.datasets.get_dataset(24) \n",
    "\n",
    "X, y, _, attribute_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "X['target'] = y\n",
    "\n",
    "X = X.drop(X.columns[[10, 15]], axis=1) # column 10 has too many NAs and column 15 has no variability\n",
    "\n",
    "num_idx = None\n",
    "cat_idx = list(range(21))\n",
    "\n",
    "X = enforce_dtypes(dat = X, \n",
    "                   num_variables = num_idx, \n",
    "                   cat_variables = cat_idx)\n",
    "\n",
    "# Split the data\n",
    "aux = train_test_data_split(X, my_seed=123)\n",
    "\n",
    "X_train = aux[\"X_train\"]\n",
    "X_test = aux[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05445afd-f860-4ec1-ba77-4aee3c0ca680",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = GenericDataLoader(\n",
    "    X_train,\n",
    "    target_column = 'target'\n",
    ")\n",
    "\n",
    "loader_test = GenericDataLoader(\n",
    "    X_test,\n",
    "    target_column = 'target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82053f12-56b6-415d-b918-b1cb8231efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthcity.benchmark import Benchmarks\n",
    "\n",
    "out_path = 'outputs/mushroom/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0be93-3ce2-445f-8ced-db218ba6d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = Benchmarks.evaluate(\n",
    "    [\n",
    "        ('TabSDS', 'syn_tab_sjppds', {'n_levels': 40, \n",
    "                                      'n_prop': 0.5, \n",
    "                                      \"num_variables\": num_idx, \n",
    "                                      \"cat_variables\": cat_idx}),\n",
    "        ('ddpm', 'ddpm', {'lr': 0.00884671824119367,\n",
    "                          'batch_size': 4093,\n",
    "                          'num_timesteps': 853,\n",
    "                          'n_iter': 5127,\n",
    "                          'is_classification': True}),\n",
    "        ('arf', 'arf', {'num_trees': 100,\n",
    "                        'delta': 0,\n",
    "                        'max_iters': 1,\n",
    "                        'early_stop': False,\n",
    "                        'min_node_size': 2}),\n",
    "        ('tvae', 'tvae', {'n_iter': 200,\n",
    "                          'lr': 0.001,\n",
    "                          'decoder_n_layers_hidden': 5,\n",
    "                          'weight_decay': 0.001,\n",
    "                          'batch_size': 512,\n",
    "                          'n_units_embedding': 150,\n",
    "                          'decoder_n_units_hidden': 150,\n",
    "                          'decoder_nonlin': 'relu',\n",
    "                          'decoder_dropout': 0.1171471896118231,\n",
    "                          'encoder_n_layers_hidden': 4,\n",
    "                          'encoder_n_units_hidden': 300,\n",
    "                          'encoder_nonlin': 'tanh',\n",
    "                          'encoder_dropout': 0.16007215982462047}),\n",
    "        ('ctgan', 'ctgan', {'generator_n_layers_hidden': 4,\n",
    "                            'generator_n_units_hidden': 50,\n",
    "                            'generator_nonlin': 'leaky_relu',\n",
    "                            'n_iter': 700,\n",
    "                            'generator_dropout': 0.020973543252274986,\n",
    "                            'discriminator_n_layers_hidden': 3,\n",
    "                            'discriminator_n_units_hidden': 150,\n",
    "                            'discriminator_nonlin': 'tanh',\n",
    "                            'discriminator_n_iter': 4,\n",
    "                            'discriminator_dropout': 0.1644064126493125,\n",
    "                            'lr': 0.001,\n",
    "                            'weight_decay': 0.001,\n",
    "                            'batch_size': 500,\n",
    "                            'encoder_max_clusters': 13}),\n",
    "        ('bayesnet', 'bayesian_network', {'struct_learning_search_method': 'hillclimb',\n",
    "                                            'struct_learning_score': 'bic'}),  \n",
    "    ],\n",
    "    X=loader_train,\n",
    "    X_test=loader_test,\n",
    "    repeats=10,\n",
    "    metrics={\"performance\": [\"xgb\"],\n",
    "             \"detection\": [\"detection_xgb\"], \n",
    "             \"privacy\": [\"DomiasMIA_KDE\", \"DomiasMIA_prior\"]},\n",
    "    task_type = \"classification\",\n",
    ")\n",
    "\n",
    "# save results\n",
    "\n",
    "synthesizer_names = ['TabSDS', 'ddpm', 'arf', 'tvae', 'ctgan', 'bayesnet']\n",
    "\n",
    "mean1 = extract_summary(score_output = score1,\n",
    "                          synthesizer_names = synthesizer_names,\n",
    "                          summary_name = \"mean\")\n",
    "stddev1 = extract_summary(score_output = score1,\n",
    "                          synthesizer_names = synthesizer_names,\n",
    "                          summary_name = \"stddev\")\n",
    "\n",
    "file_name = os.path.join(out_path, \"mushroom_optuna_mean1.csv\")\n",
    "mean1.to_csv(file_name, index = True)\n",
    "\n",
    "file_name = os.path.join(out_path, \"mushroom_optuna_stddev1.csv\")\n",
    "stddev1.to_csv(file_name, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce243e-b04f-4cc2-af94-b9771b3a9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "Benchmarks.print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b61ecb-9c32-4322-ab14-fe46808bcaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = 'outputs/mushroom/simulated_datasets/'\n",
    "\n",
    "file_name = os.path.join(out_path, 'train_set.csv')\n",
    "X_train.to_csv(file_name, index = False)\n",
    "\n",
    "file_name = os.path.join(out_path, 'test_set.csv')\n",
    "X_test.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a434f7f6-2207-476d-9a7b-64e6614f95b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddpm\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "syn_model = Plugins().get('ddpm',\n",
    "                          n_iter = 5127,\n",
    "                          lr = 0.00884671824119367,\n",
    "                          batch_size = 4093,\n",
    "                          num_timesteps = 853,\n",
    "                          is_classification = True)\n",
    "\n",
    "syn_model.fit(loader_train)\n",
    "\n",
    "n = len(loader_train)\n",
    "Y = syn_model.generate(count=n).dataframe()\n",
    "\n",
    "file_name = os.path.join(out_path, 'syn_ddpm.csv')\n",
    "Y.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f37b9-25ed-4b68-b0b0-7599d89178f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arf\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "syn_model = Plugins().get('arf',\n",
    "                         num_trees = 100,\n",
    "                          delta = 0,\n",
    "                          max_iters = 1,\n",
    "                          early_stop = False,\n",
    "                          min_node_size = 2)\n",
    "\n",
    "syn_model.fit(loader_train)\n",
    "\n",
    "n = len(loader_train)\n",
    "Y = syn_model.generate(count=n).dataframe()\n",
    "\n",
    "file_name = os.path.join(out_path, 'syn_arf.csv')\n",
    "Y.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bdd5b9-8f2f-4cb4-b1c3-235676444c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvae\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "syn_model = Plugins().get('tvae',\n",
    "                          n_iter = 200,\n",
    "                          lr = 0.001,\n",
    "                          decoder_n_layers_hidden = 5,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 512,\n",
    "                          n_units_embedding = 150,\n",
    "                          decoder_n_units_hidden = 150,\n",
    "                          decoder_nonlin = 'relu',\n",
    "                          decoder_dropout = 0.1171471896118231,\n",
    "                          encoder_n_layers_hidden = 4,\n",
    "                          encoder_n_units_hidden = 300,\n",
    "                          encoder_nonlin = 'tanh',\n",
    "                          encoder_dropout = 0.16007215982462047)\n",
    "\n",
    "syn_model.fit(loader_train)\n",
    "\n",
    "n = len(loader_train)\n",
    "Y = syn_model.generate(count=n).dataframe()\n",
    "\n",
    "file_name = os.path.join(out_path, 'syn_tvae.csv')\n",
    "Y.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a28481e-cb39-4a37-ab8b-e77719992522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctgan\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "syn_model = Plugins().get('ctgan',\n",
    "                          generator_n_layers_hidden = 4,\n",
    "                          generator_n_units_hidden = 50,\n",
    "                          generator_nonlin = 'leaky_relu',\n",
    "                          n_iter = 700,\n",
    "                          generator_dropout = 0.020973543252274986,\n",
    "                          discriminator_n_layers_hidden = 3,\n",
    "                          discriminator_n_units_hidden = 150,\n",
    "                          discriminator_nonlin = 'tanh',\n",
    "                          discriminator_n_iter = 4,\n",
    "                          discriminator_dropout = 0.1644064126493125,\n",
    "                          lr = 0.001,\n",
    "                          weight_decay = 0.001,\n",
    "                          batch_size = 500,\n",
    "                          encoder_max_clusters = 13)\n",
    "\n",
    "syn_model.fit(loader_train)\n",
    "\n",
    "n = len(loader_train)\n",
    "Y = syn_model.generate(count=n).dataframe()\n",
    "\n",
    "file_name = os.path.join(out_path, 'syn_ctgan.csv')\n",
    "Y.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ec915-9809-4668-a03e-fb3457d336cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesnet\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "syn_model = Plugins().get('bayesian_network',\n",
    "                          struct_learning_search_method = 'hillclimb',\n",
    "                          struct_learning_score = 'bic')\n",
    "\n",
    "syn_model.fit(loader_train)\n",
    "\n",
    "n = len(loader_train)\n",
    "Y = syn_model.generate(count=n).dataframe()\n",
    "\n",
    "file_name = os.path.join(out_path, 'syn_bayesnet.csv')\n",
    "Y.to_csv(file_name, index = False)# bayesnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970238d8-ac85-4e3c-a0c5-3dfdb1683e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syn_tab_sjppds\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "syn_model = Plugins().get('syn_tab_sjppds', \n",
    "                          num_variables = num_idx,\n",
    "                          cat_variables = cat_idx,\n",
    "                          n_levels = 40,\n",
    "                         n_prop = 0.5)\n",
    "\n",
    "syn_model.fit(loader_train)\n",
    "\n",
    "n = len(loader_train)\n",
    "Y = syn_model.generate(count=n).dataframe()\n",
    "\n",
    "file_name = os.path.join(out_path, 'syn_tab_sjppds_40_0.5.csv')\n",
    "Y.to_csv(file_name, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
